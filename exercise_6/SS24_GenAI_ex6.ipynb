{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torchvision import models, datasets, transforms\n",
    "from network import Autoencoder, Conv_Autoencoder, add_white_noise\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Training Loss: 0.1608\n",
      "Epoch [2/50], Training Loss: 0.1060\n",
      "Epoch [3/50], Training Loss: 0.1001\n",
      "Epoch [4/50], Training Loss: 0.0972\n",
      "Epoch [5/50], Training Loss: 0.0951\n",
      "Epoch [6/50], Training Loss: 0.0935\n",
      "Epoch [7/50], Training Loss: 0.0921\n",
      "Epoch [8/50], Training Loss: 0.0912\n",
      "Epoch [9/50], Training Loss: 0.0903\n",
      "Epoch [10/50], Training Loss: 0.0897\n",
      "Epoch [10/50], Test Loss: 0.0900\n",
      "Epoch [11/50], Training Loss: 0.0890\n",
      "Epoch [12/50], Training Loss: 0.0885\n",
      "Epoch [13/50], Training Loss: 0.0881\n",
      "Epoch [14/50], Training Loss: 0.0877\n",
      "Epoch [15/50], Training Loss: 0.0874\n",
      "Epoch [16/50], Training Loss: 0.0870\n",
      "Epoch [17/50], Training Loss: 0.0868\n",
      "Epoch [18/50], Training Loss: 0.0867\n",
      "Epoch [19/50], Training Loss: 0.0864\n",
      "Epoch [20/50], Training Loss: 0.0861\n",
      "Epoch [20/50], Test Loss: 0.0871\n",
      "Epoch [21/50], Training Loss: 0.0859\n",
      "Epoch [22/50], Training Loss: 0.0856\n",
      "Epoch [23/50], Training Loss: 0.0853\n",
      "Epoch [24/50], Training Loss: 0.0852\n",
      "Epoch [25/50], Training Loss: 0.0850\n",
      "Epoch [26/50], Training Loss: 0.0848\n",
      "Epoch [27/50], Training Loss: 0.0848\n",
      "Epoch [28/50], Training Loss: 0.0845\n",
      "Epoch [29/50], Training Loss: 0.0845\n",
      "Epoch [30/50], Training Loss: 0.0842\n",
      "Epoch [30/50], Test Loss: 0.0851\n",
      "Epoch [31/50], Training Loss: 0.0842\n",
      "Epoch [32/50], Training Loss: 0.0840\n",
      "Epoch [33/50], Training Loss: 0.0839\n",
      "Epoch [34/50], Training Loss: 0.0843\n",
      "Epoch [35/50], Training Loss: 0.0835\n",
      "Epoch [36/50], Training Loss: 0.0839\n",
      "Epoch [37/50], Training Loss: 0.0838\n",
      "Epoch [38/50], Training Loss: 0.0836\n",
      "Epoch [39/50], Training Loss: 0.0834\n",
      "Epoch [40/50], Training Loss: 0.0832\n",
      "Epoch [40/50], Test Loss: 0.0841\n",
      "Epoch [41/50], Training Loss: 0.0831\n",
      "Epoch [42/50], Training Loss: 0.0834\n",
      "Epoch [43/50], Training Loss: 0.0834\n",
      "Epoch [44/50], Training Loss: 0.0836\n",
      "Epoch [45/50], Training Loss: 0.0830\n",
      "Epoch [46/50], Training Loss: 0.0831\n",
      "Epoch [47/50], Training Loss: 0.0827\n",
      "Epoch [48/50], Training Loss: 0.0831\n",
      "Epoch [49/50], Training Loss: 0.0831\n",
      "Epoch [50/50], Training Loss: 0.0833\n",
      "Epoch [50/50], Test Loss: 0.0833\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (50,) and (5,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m     59\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), train_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), test_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     61\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     62\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gen-ai/lib/python3.11/site-packages/matplotlib/pyplot.py:3590\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3582\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3584\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3588\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m   3591\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m   3592\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[1;32m   3593\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[1;32m   3594\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m   3595\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3596\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gen-ai/lib/python3.11/site-packages/matplotlib/axes/_axes.py:1724\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1724\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1725\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1726\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gen-ai/lib/python3.11/site-packages/matplotlib/axes/_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_args(\n\u001b[1;32m    304\u001b[0m     axes, this, kwargs, ambiguous_fmt_datakey\u001b[38;5;241m=\u001b[39mambiguous_fmt_datakey)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gen-ai/lib/python3.11/site-packages/matplotlib/axes/_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (5,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "#Fashion NIST data has form 1x1x28x28 (grayscale)\n",
    "\n",
    "autoencoder = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "num_epochs = 50\n",
    "\n",
    "# Lists to store loss values\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Training and testing\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    autoencoder.train()\n",
    "    for data in train_loader:\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)  # Flatten the images\n",
    "        output = autoencoder(img)\n",
    "        loss = criterion(output, img)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}')\n",
    "    \n",
    "    # Evaluate on the test set every ten epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        test_loss = 0\n",
    "        autoencoder.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                img, _ = data\n",
    "                img = img.view(img.size(0), -1)  # Flatten the images\n",
    "                output = autoencoder(img)\n",
    "                loss = criterion(output, img)\n",
    "                test_loss += loss.item()\n",
    "        \n",
    "        test_loss /= len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Test Loss: {test_loss:.4f}')\n",
    "\n",
    "\n",
    "# Plotting the training and test loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs+1), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Training Loss: 0.0687\n",
      "Epoch [2/50], Training Loss: 0.0679\n",
      "Epoch [3/50], Training Loss: 0.0677\n",
      "Epoch [4/50], Training Loss: 0.0675\n",
      "Epoch [5/50], Training Loss: 0.0673\n",
      "Epoch [6/50], Training Loss: 0.0672\n",
      "Epoch [7/50], Training Loss: 0.0669\n",
      "Epoch [8/50], Training Loss: 0.0663\n",
      "Epoch [9/50], Training Loss: 0.0660\n",
      "Epoch [10/50], Training Loss: 0.0656\n",
      "Epoch [10/50], Test Loss: 0.0663\n",
      "Epoch [11/50], Training Loss: 0.0654\n",
      "Epoch [12/50], Training Loss: 0.0652\n",
      "Epoch [13/50], Training Loss: 0.0649\n",
      "Epoch [14/50], Training Loss: 0.0648\n",
      "Epoch [15/50], Training Loss: 0.0645\n",
      "Epoch [16/50], Training Loss: 0.0644\n",
      "Epoch [17/50], Training Loss: 0.0643\n",
      "Epoch [18/50], Training Loss: 0.0642\n",
      "Epoch [19/50], Training Loss: 0.0641\n",
      "Epoch [20/50], Training Loss: 0.0640\n",
      "Epoch [20/50], Test Loss: 0.0646\n",
      "Epoch [21/50], Training Loss: 0.0640\n",
      "Epoch [22/50], Training Loss: 0.0638\n",
      "Epoch [23/50], Training Loss: 0.0637\n",
      "Epoch [24/50], Training Loss: 0.0637\n",
      "Epoch [25/50], Training Loss: 0.0636\n",
      "Epoch [26/50], Training Loss: 0.0635\n",
      "Epoch [27/50], Training Loss: 0.0635\n",
      "Epoch [28/50], Training Loss: 0.0634\n",
      "Epoch [29/50], Training Loss: 0.0634\n",
      "Epoch [30/50], Training Loss: 0.0634\n",
      "Epoch [30/50], Test Loss: 0.0640\n",
      "Epoch [31/50], Training Loss: 0.0633\n",
      "Epoch [32/50], Training Loss: 0.0633\n",
      "Epoch [33/50], Training Loss: 0.0633\n",
      "Epoch [34/50], Training Loss: 0.0632\n",
      "Epoch [35/50], Training Loss: 0.0631\n",
      "Epoch [36/50], Training Loss: 0.0631\n",
      "Epoch [37/50], Training Loss: 0.0630\n",
      "Epoch [38/50], Training Loss: 0.0629\n",
      "Epoch [39/50], Training Loss: 0.0629\n",
      "Epoch [40/50], Training Loss: 0.0629\n",
      "Epoch [40/50], Test Loss: 0.0641\n",
      "Epoch [41/50], Training Loss: 0.0628\n",
      "Epoch [42/50], Training Loss: 0.0628\n",
      "Epoch [43/50], Training Loss: 0.0628\n",
      "Epoch [44/50], Training Loss: 0.0628\n",
      "Epoch [45/50], Training Loss: 0.0627\n",
      "Epoch [46/50], Training Loss: 0.0628\n",
      "Epoch [47/50], Training Loss: 0.0627\n",
      "Epoch [48/50], Training Loss: 0.0626\n",
      "Epoch [49/50], Training Loss: 0.0625\n",
      "Epoch [50/50], Training Loss: 0.0625\n",
      "Epoch [50/50], Test Loss: 0.0633\n"
     ]
    }
   ],
   "source": [
    "# Training and testing\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    autoencoder.train()\n",
    "    for data in train_loader:\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)  # Flatten the images\n",
    "        noisy_img = add_white_noise(img)       # Add noise to the images\n",
    "        output = autoencoder(noisy_img)\n",
    "        loss = criterion(output, img)    # Compute loss with respect to original images\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}')\n",
    "    \n",
    "    # Evaluate on the test set every ten epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        test_loss = 0\n",
    "        autoencoder.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                img, _ = data\n",
    "                img = img.view(img.size(0), -1)  # Flatten the images\n",
    "                noisy_img = add_white_noise(img)       # Add noise to the images\n",
    "                output = autoencoder(noisy_img)\n",
    "                loss = criterion(output, img)    # Compute loss with respect to original images\n",
    "                test_loss += loss.item()\n",
    "        \n",
    "        test_loss /= len(test_loader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m Conv_Autoencoder()\n\u001b[1;32m     10\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m---> 11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(autoencoder\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Number of epochs\u001b[39;00m\n\u001b[1;32m     14\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gen-ai/lib/python3.11/site-packages/torch/optim/adam.py:45\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39mbetas, eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m     42\u001b[0m                 weight_decay\u001b[38;5;241m=\u001b[39mweight_decay, amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m     43\u001b[0m                 maximize\u001b[38;5;241m=\u001b[39mmaximize, foreach\u001b[38;5;241m=\u001b[39mforeach, capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m     44\u001b[0m                 differentiable\u001b[38;5;241m=\u001b[39mdifferentiable, fused\u001b[38;5;241m=\u001b[39mfused)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(params, defaults)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gen-ai/lib/python3.11/site-packages/torch/optim/optimizer.py:273\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    271\u001b[0m param_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(params)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer got an empty parameter list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param_groups[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    275\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n",
      "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "# Data loading and transformation\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Model, loss function, and optimizer\n",
    "autoencoder = Conv_Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
